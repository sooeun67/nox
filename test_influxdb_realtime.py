import logging
import pandas as pd
import numpy as np
from data_preprocessor import NOxDataPreprocessor
import pickle
import os
import sys
from datetime import datetime, timedelta
from influxdb import InfluxDBClient

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)


class SRS1InfluxDBClient:
    """SRS1 InfluxDB í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self):
        # ê°œë°œ InfluxDB ì„¤ì •
        self.client = InfluxDBClient(
            host="10.238.24.150",
            port=8086,
            username="read_user",
            password="!Skepinfluxuser25",
            database="SRS1",
        )
        self.database = "SRS1"

    def _make_read_query(
        self,
        columns: list,
        start_time: pd.Timestamp,
        query_range_seconds: int,
        table_name: str = "SRS1",
    ) -> str:
        """ì‹œê°„ ë²”ìœ„ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±"""
        end_time = start_time - pd.Timedelta(seconds=query_range_seconds)
        start_time_str = start_time.strftime("%Y-%m-%d %H:%M:%S")
        end_time_str = end_time.strftime("%Y-%m-%d %H:%M:%S")

        query = f"""
            SELECT {",".join(columns)}
            FROM {table_name}
            WHERE time > '{end_time_str}' and time <= '{start_time_str}'
            ORDER BY time
        """
        return query

    def read_data(
        self,
        columns: list,
        start_time: pd.Timestamp,
        query_range_seconds: int,
        table_name: str = "SRS1",
    ) -> pd.DataFrame:
        """SRS1 ë°ì´í„° ì¡°íšŒ"""
        try:
            query = self._make_read_query(
                columns, start_time, query_range_seconds, table_name
            )
            print(f"ğŸ” ì¿¼ë¦¬ ì‹¤í–‰: {query_range_seconds}ì´ˆ ë²”ìœ„")

            result_set = self.client.query(query)
            data = pd.DataFrame(result_set.get_points())

            if data.empty:
                print("âš ï¸ ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()

            # ì‹œê°„ ì»¬ëŸ¼ì„ _time_gatewayë¡œ ë³€í™˜
            if "time" in data.columns:
                data["_time_gateway"] = pd.to_datetime(data["time"])
                data = data.drop(columns=["time"])

            # ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜ (InfluxDBëŠ” ëŒ€ë¬¸ì, ìš°ë¦¬ ì½”ë“œëŠ” ì†Œë¬¸ì)
            column_mapping = {}
            for col in data.columns:
                if col != "_time_gateway":
                    column_mapping[col] = col.lower()

            data = data.rename(columns=column_mapping)

            print(f"âœ… ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {data.shape}")
            print(f"   ì»¬ëŸ¼: {list(data.columns)}")
            print(
                f"   ì‹œê°„ ë²”ìœ„: {data['_time_gateway'].min()} ~ {data['_time_gateway'].max()}"
            )

            return data

        except Exception as e:
            print(f"âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            import traceback

            traceback.print_exc()
            return pd.DataFrame()


def test_influxdb_connection():
    """InfluxDB ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ”Œ InfluxDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    try:
        client = SRS1InfluxDBClient()

        # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
        test_query = "SHOW MEASUREMENTS"
        result = client.client.query(test_query)

        print("âœ… InfluxDB ì—°ê²° ì„±ê³µ")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”: {list(result.get_points())}")
        return client

    except Exception as e:
        print(f"âŒ InfluxDB ì—°ê²° ì‹¤íŒ¨: {e}")
        return None


def fetch_realtime_data(client: SRS1InfluxDBClient):
    """ì‹¤ì‹œê°„ SRS1 ë°ì´í„° ì¡°íšŒ"""
    print("ğŸ“Š ì‹¤ì‹œê°„ SRS1 ë°ì´í„° ì¡°íšŒ ì‹œì‘")
    print("=" * 60)

    try:
        # NOx ì˜ˆì¸¡ì— í•„ìš”í•œ ì»¬ëŸ¼ë“¤ (ëŒ€ë¬¸ìë¡œ InfluxDBì—ì„œ ì¡°íšŒ)
        columns = [
            "_time_gateway",
            "BFT_EO_FG_T",
            "BR1_EO_FG_T",
            "BR1_EO_O2_A",
            "BR1_EO_ST_T",
            "DR1_EQ_BW_C",
            "ICF_CCS_FG_T_1",
            "ICF_CRA_WT_K",
            "ICF_FF1_AR_F_1",
            "ICF_FF1_SS_S_1",
            "ICF_FF1_SS_S_2",
            "ICF_FF2_SS_S_1",
            "ICF_IDF_SS_S_1",
            "ICF_SCS_FG_T_1",
            "ICF_TMS_NOX_A",
            "SDR_HTR_FG_T",
            "NOX_Value",
        ]

        # í˜„ì¬ ì‹œê°„ë¶€í„° 1ì‹œê°„ ì „ê¹Œì§€ ë°ì´í„° ì¡°íšŒ
        end_time = pd.Timestamp.now()
        start_time = end_time - pd.Timedelta(hours=1)
        query_range_seconds = 3600  # 1ì‹œê°„

        print(f"â° ì¡°íšŒ ê¸°ê°„: {start_time} ~ {end_time}")

        # ë°ì´í„° ì¡°íšŒ
        raw_data = client.read_data(
            columns=columns,
            start_time=end_time,
            query_range_seconds=query_range_seconds,
            table_name="SRS1",
        )

        if not raw_data.empty:
            print(f"âœ… ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {raw_data.shape}")
            return raw_data
        else:
            print("âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            return None

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        return None


def test_full_pipeline(client: SRS1InfluxDBClient):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”„ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1. ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ
    raw_data = fetch_realtime_data(client)
    if raw_data is None or raw_data.empty:
        print("âŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
        return None

    print(f"\nğŸ“Š ì›ë³¸ ë°ì´í„° ì •ë³´:")
    print(f"   ë°ì´í„° í˜•íƒœ: {raw_data.shape}")
    print(f"   ì»¬ëŸ¼ ìˆ˜: {len(raw_data.columns)}")
    print(
        f"   ì‹œê°„ ë²”ìœ„: {raw_data['_time_gateway'].min()} ~ {raw_data['_time_gateway'].max()}"
    )
    print(f"   ìƒ˜í”Œ ì»¬ëŸ¼: {list(raw_data.columns[:10])}")

    # 2. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print("\nğŸ”„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
    preprocessor = NOxDataPreprocessor()
    try:
        processed_data, feature_cols = preprocessor.preprocess_realtime_data(raw_data)
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {processed_data.shape}")
        print(f"   ìƒì„±ëœ í”¼ì²˜ ìˆ˜: {len(feature_cols)}")

        # ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼ í™•ì¸ - ë” ìì„¸í•œ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ” ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼ í™•ì¸:")
        print(f"   ì „ì²´ ì»¬ëŸ¼ ìˆ˜: {len(processed_data.columns)}")
        print(
            f"   NOx ê´€ë ¨ ì»¬ëŸ¼: {[col for col in processed_data.columns if 'nox' in col.lower()]}"
        )
        print(
            f"   ì‹œê°„ ê´€ë ¨ ì»¬ëŸ¼: {[col for col in processed_data.columns if 'time' in col.lower()]}"
        )

        # ì›ë³¸ NOx ì»¬ëŸ¼ í™•ì¸
        print(
            f"   ì›ë³¸ NOx ì»¬ëŸ¼ (nox_value): {[col for col in processed_data.columns if col == 'nox_value']}"
        )
        print(
            f"   icf_tms_nox_a ê´€ë ¨ ì»¬ëŸ¼: {[col for col in processed_data.columns if 'icf_tms_nox_a' in col][:5]}"
        )

        # ì „ì²´ ì»¬ëŸ¼ì—ì„œ 'nox'ê°€ í¬í•¨ëœ ì»¬ëŸ¼ ìƒì„¸ í™•ì¸
        nox_columns = [col for col in processed_data.columns if "nox" in col.lower()]
        print(f"   NOx ê´€ë ¨ ì»¬ëŸ¼ ìƒì„¸:")
        for i, col in enumerate(nox_columns[:10]):  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"     {i+1:2d}. {col}")
        if len(nox_columns) > 10:
            print(f"     ... ì™¸ {len(nox_columns) - 10}ê°œ")

        # ì›ë³¸ ë°ì´í„°ì—ì„œ NOx ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
        print(f"\nğŸ” ì›ë³¸ ë°ì´í„° NOx ì»¬ëŸ¼ í™•ì¸:")
        print(f"   ì›ë³¸ ì»¬ëŸ¼: {list(raw_data.columns)}")
        print(
            f"   NOx ê´€ë ¨ ì›ë³¸ ì»¬ëŸ¼: {[col for col in raw_data.columns if 'nox' in col.lower()]}"
        )

        # ì „ì²˜ë¦¬ ì „í›„ ì»¬ëŸ¼ ë¹„êµ
        print(f"\nğŸ” ì „ì²˜ë¦¬ ì „í›„ ì»¬ëŸ¼ ë¹„êµ:")
        print(
            f"   ì „ì²˜ë¦¬ ì „ NOx ì»¬ëŸ¼: {[col for col in raw_data.columns if 'nox' in col.lower()]}"
        )
        print(
            f"   ì „ì²˜ë¦¬ í›„ NOx ì»¬ëŸ¼: {[col for col in processed_data.columns if 'nox' in col.lower()]}"
        )

        # 3. ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰
        print("\nğŸ¤– ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
        with open("Model/lgbm_model.pkl", "rb") as f:
            model = pickle.load(f)

        model_features = model.feature_names_in_
        available_features = [f for f in model_features if f in feature_cols]
        missing_features = [f for f in model_features if f not in feature_cols]

        print(f"ğŸ” í”¼ì²˜ ë§¤ì¹­ ê²°ê³¼:")
        print(f"   ëª¨ë¸ í”¼ì²˜ ìˆ˜: {len(model_features)}")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {len(available_features)}ê°œ")
        print(f"   ëˆ„ë½ëœ í”¼ì²˜: {len(missing_features)}ê°œ")

        if missing_features:
            print(f"   âš ï¸ ëˆ„ë½ëœ í”¼ì²˜ (ì²˜ìŒ 10ê°œ): {missing_features[:10]}")
            if len(missing_features) > 10:
                print(f"   ... ì™¸ {len(missing_features) - 10}ê°œ")

        if len(available_features) > 0:
            model_input = processed_data[available_features].fillna(0)

            print(f"\nğŸš€ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
            print(f"   ì…ë ¥ ë°ì´í„° í˜•íƒœ: {model_input.shape}")

            predictions = model.predict(model_input)

            print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ")
            print(f"   ì˜ˆì¸¡ê°’ ë²”ìœ„: {predictions.min():.2f} ~ {predictions.max():.2f}")
            print(f"   ì˜ˆì¸¡ê°’ í‰ê· : {predictions.mean():.2f}")
            print(f"   ì˜ˆì¸¡ê°’ í‘œì¤€í¸ì°¨: {predictions.std():.2f}")

            # 4. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            result_df = processed_data.copy()
            result_df["nox_prediction"] = predictions

            # ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³µì› (ì¤‘ìš”!)
            if result_df.index.name == "_time_gateway":
                result_df = result_df.reset_index()
                print("âœ… _time_gateway ì¸ë±ìŠ¤ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³µì›")

            # NOX_Valueë¥¼ ë³„ë„ë¡œ ì¶”ê°€ (Yê°’ìœ¼ë¡œ ì‚¬ìš©)
            if "nox_value" in raw_data.columns:
                result_df["nox_value"] = raw_data["nox_value"]
                print("âœ… nox_value (Yê°’) ì¶”ê°€")

            # 5. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ì¶œë ¥
            print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼ ë°ì´í„°:")
            print(f"   ë°ì´í„° í˜•íƒœ: {result_df.shape}")
            print(f"   ì»¬ëŸ¼ ìˆ˜: {len(result_df.columns)}")

            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = [
                "_time_gateway",
                "nox_value",
                "nox_prediction",
                "br1_eo_o2_a",
                "icf_scs_fg_t_1",
                "icf_ccs_fg_t_1",
            ]

            available_required = [
                col for col in required_columns if col in result_df.columns
            ]
            missing_required = [
                col for col in required_columns if col not in result_df.columns
            ]

            print(f"\nğŸ” í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸:")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_required}")
            if missing_required:
                print(f"   âš ï¸ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_required}")

            # 6. ë§ˆì§€ë§‰ 10ê°œ í–‰ ì¶œë ¥
            if len(available_required) > 0:
                print(f"\nğŸ“‹ ë§ˆì§€ë§‰ 10ê°œ í–‰ (í•„ìˆ˜ ì»¬ëŸ¼):")
                print("=" * 80)

                # ë§ˆì§€ë§‰ 10ê°œ í–‰ ì„ íƒ
                last_10_rows = result_df[available_required].tail(10)

                # ì‹œê°„ í¬ë§·íŒ…
                if "_time_gateway" in last_10_rows.columns:
                    last_10_rows["_time_gateway"] = last_10_rows[
                        "_time_gateway"
                    ].dt.strftime("%Y-%m-%d %H:%M:%S")

                # ë°ì´í„° ì¶œë ¥
                pd.set_option("display.max_columns", None)
                pd.set_option("display.width", None)
                print(last_10_rows.to_string(index=False))

                # 7. í†µê³„ ìš”ì•½
                print(f"\nğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼ í†µê³„:")
                print(f"   ì˜ˆì¸¡ê°’ í‰ê· : {result_df['nox_prediction'].mean():.2f}")
                print(f"   ì˜ˆì¸¡ê°’ ì¤‘ì•™ê°’: {result_df['nox_prediction'].median():.2f}")
                print(f"   ì˜ˆì¸¡ê°’ í‘œì¤€í¸ì°¨: {result_df['nox_prediction'].std():.2f}")

                if "nox_value" in result_df.columns:
                    print(f"\nğŸ” ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ ë¹„êµ:")
                    print(f"   ì‹¤ì œê°’ í‰ê· : {result_df['nox_value'].mean():.2f}")
                    print(f"   ì˜ˆì¸¡ê°’ í‰ê· : {result_df['nox_prediction'].mean():.2f}")
                    print(
                        f"   ì°¨ì´ í‰ê· : {abs(result_df['nox_value'] - result_df['nox_prediction']).mean():.2f}"
                    )

            return result_df
        else:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    except Exception as e:
        print(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()
        return None


if __name__ == "__main__":
    print("ğŸš€ SRS1 InfluxDB ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1. InfluxDB ì—°ê²° í…ŒìŠ¤íŠ¸
    client = test_influxdb_connection()
    if client:
        # 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        result = test_full_pipeline(client)

        if result is not None:
            print("\nğŸŠ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print("ì‹¤ì‹œê°„ SRS1 InfluxDB íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        else:
            print("\nâš ï¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    else:
        print("\nâŒ InfluxDB ì—°ê²° ì‹¤íŒ¨")
