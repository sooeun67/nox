import logging
import pandas as pd
import numpy as np
from data_preprocessor import NOxDataPreprocessor
import os

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)


def load_real_data():
    """ì‹¤ì œ parquet ë°ì´í„°ì—ì„œ íŠ¹ì • ê¸°ê°„ ë¡œë“œ"""
    print("ğŸ“Š ì‹¤ì œ parquet ë°ì´í„° ë¡œë“œ ì¤‘...")

    try:
        # parquet íŒŒì¼ ê²½ë¡œ
        file_path = "Data/cleaned_240411_250724.parquet"

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return None

        print(f"ì „ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼: {file_path}")

        # íŠ¹ì • ê¸°ê°„ ë°ì´í„°ë§Œ ë¡œë“œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        start_date = "2025-07-01"
        end_date = "2025-07-10"

        print(f"ì „ì²˜ë¦¬ ëŒ€ìƒ ë°ì´í„° ê¸°ê°„: {start_date} ~ {end_date}")

        # parquet íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
        data = pd.read_parquet(file_path)
        print(f"   ğŸ“Š ì „ì²´ ë°ì´í„°: {data.shape}")

        # _time_gateway ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
        if "_time_gateway" in data.columns:
            data["_time_gateway"] = pd.to_datetime(data["_time_gateway"])

            # íŠ¹ì • ê¸°ê°„ í•„í„°ë§
            mask = (data["_time_gateway"] >= start_date) & (
                data["_time_gateway"] <= end_date
            )
            data = data[mask].copy()

            print(f"âœ… í•„í„°ë§ ì™„ë£Œ: {data.shape}")
            print(
                f"ğŸ“… ì‹œê°„ ë²”ìœ„: {data['_time_gateway'].min()} ~ {data['_time_gateway'].max()}"
            )

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            data = data.reset_index(drop=True)

            return data
        else:
            print("âŒ _time_gateway ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        return None


def test_preprocessing():
    """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª NOx ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1. ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    sample_data = load_real_data()

    if sample_data is None:
        print("âŒ ë°ì´í„° ë¡œë“œë¥¼ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return None, None

    # 2. ì „ì²˜ë¦¬ ì‹¤í–‰
    print("\nğŸš€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
    preprocessor = NOxDataPreprocessor()

    try:
        processed_data, feature_cols = preprocessor.preprocess_realtime_data(
            sample_data
        )

        print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ìµœì¢… ë°ì´í„° í˜•íƒœ: {processed_data.shape}")
        print(f"ğŸ”¢ í”¼ì²˜ ìˆ˜: {len(feature_cols)}")
        print(f"ğŸ“‹ í”¼ì²˜ ëª©ë¡ (ì²˜ìŒ 15ê°œ):")
        for i, feature in enumerate(feature_cols[:15]):
            print(f"   {i+1:2d}. {feature}")

        if len(feature_cols) > 15:
            print(f"   ... ì™¸ {len(feature_cols) - 15}ê°œ")

        # 3. ë°ì´í„° í’ˆì§ˆ í™•ì¸
        print("\nğŸ” ë°ì´í„° í’ˆì§ˆ í™•ì¸:")
        print(f"ê²°ì¸¡ì¹˜: {processed_data.isna().sum().sum()}ê°œ")
        print(
            f"ë¬´í•œê°’: {np.isinf(processed_data.select_dtypes(include=[np.number])).sum().sum()}ê°œ"
        )
        print(
            f"ìŒì˜ ë¬´í•œê°’: {np.isneginf(processed_data.select_dtypes(include=[np.number])).sum().sum()}ê°œ"
        )

        # 4. í”¼ì²˜ë³„ í†µê³„ ì •ë³´
        print("\nğŸ“ˆ í”¼ì²˜ë³„ ê¸°ë³¸ í†µê³„:")
        numeric_cols = processed_data.select_dtypes(include=[np.number]).columns
        stats_df = processed_data[numeric_cols].describe()
        print(stats_df.round(3))

        return processed_data, feature_cols

    except Exception as e:
        print(f"\nâŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()
        return None, None


def test_with_real_model(processed_data, feature_cols):
    """ì‹¤ì œ ëª¨ë¸ê³¼ í•¨ê»˜ í…ŒìŠ¤íŠ¸ - í”¼ì²˜ ë§¤ì¹­ ì ìš©"""
    print("\nğŸ¤– ì‹¤ì œ ëª¨ë¸ê³¼ í•¨ê»˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        # ëª¨ë¸ ë¡œë“œ
        import pickle

        with open("Model/lgbm_model.pkl", "rb") as f:
            model = pickle.load(f)

        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {type(model).__name__}")

        # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í”¼ì²˜ í™•ì¸
        model_features = model.feature_names_in_
        print(f"   ëª¨ë¸ í”¼ì²˜ ìˆ˜: {len(model_features)}")
        print(f"   ì „ì²˜ë¦¬ í”¼ì²˜ ìˆ˜: {len(feature_cols)}")

        # ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ ì°¾ê¸°
        available_features = [f for f in model_features if f in feature_cols]
        missing_features = [f for f in model_features if f not in feature_cols]

        print(f"\nğŸ” í”¼ì²˜ ë§¤ì¹­ ê²°ê³¼:")
        print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {len(available_features)}ê°œ")
        print(f"   ëˆ„ë½ëœ í”¼ì²˜: {len(missing_features)}ê°œ")

        if missing_features:
            print(f"   âš ï¸ ëˆ„ë½ëœ í”¼ì²˜ (ì²˜ìŒ 10ê°œ): {missing_features[:10]}")
            if len(missing_features) > 10:
                print(f"   ... ì™¸ {len(missing_features) - 10}ê°œ")

        if len(available_features) > 0:
            # ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ë§Œìœ¼ë¡œ ì˜ˆì¸¡
            model_input = processed_data[available_features].fillna(0)

            print(f"\nğŸš€ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
            print(f"   ì…ë ¥ ë°ì´í„° í˜•íƒœ: {model_input.shape}")

            # ì˜ˆì¸¡ ì‹¤í–‰
            predictions = model.predict(model_input)

            print(f"\nğŸ”® ì˜ˆì¸¡ ì™„ë£Œ!")
            print(f"   ì˜ˆì¸¡ ë°ì´í„° ìˆ˜: {len(predictions)}")
            print(f"   ì˜ˆì¸¡ê°’ ë²”ìœ„: {predictions.min():.2f} ~ {predictions.max():.2f}")
            print(f"   ì˜ˆì¸¡ê°’ í‰ê· : {predictions.mean():.2f}")

            # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
            result_df = processed_data.copy()
            result_df["nox_prediction"] = predictions

            print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼ ë°ì´í„°:")
            print(f"   ë°ì´í„° í˜•íƒœ: {result_df.shape}")
            print(f"   ì»¬ëŸ¼ ìˆ˜: {len(result_df.columns)}")

            return result_df
        else:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()

    return None


if __name__ == "__main__":
    print("ğŸš€ NOx ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1ë‹¨ê³„: ê¸°ë³¸ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (1íšŒë§Œ ì‹¤í–‰)
    processed_data, feature_cols = test_preprocessing()

    if processed_data is not None:
        print("\nğŸ‰ ê¸°ë³¸ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")

        # 2ë‹¨ê³„: ì‹¤ì œ ëª¨ë¸ê³¼ í•¨ê»˜ í…ŒìŠ¤íŠ¸ (ì „ì²˜ë¦¬ ê²°ê³¼ ì¬ì‚¬ìš©)
        print("\n" + "=" * 60)
        result_df = test_with_real_model(
            processed_data, feature_cols
        )  # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì „ë‹¬

        if result_df is not None:
            print("\nğŸŠ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            print("ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        else:
            print("\nâš ï¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ì—ˆì§€ë§Œ, ì „ì²˜ë¦¬ëŠ” ì„±ê³µí–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print("ì½”ë“œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
